{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归 编程实践练习\n",
    "\n",
    "**说明** \n",
    "\n",
    "基于 Andrew Ng的机器学习课程编程作业制作， 使用他的作业pdf里的步骤， 尽量细化步骤并添加一些数学公式， 让人多理解算法及数学推导过程。 \n",
    "\n",
    "\n",
    "** 使用说明 **\n",
    "\n",
    "1. 尽量做到每一步有说明， 保留一个空代码块供编辑， 方便下载到本地或支持ipython notebook的网站上进行练习。\n",
    "2. 有本人实现的代码方案， 但暂时隐藏。\n",
    "3. 有心练习的话， 每次新建副本， 不看其他参考， 重新实现。\n",
    "\n",
    "首先导入一些 python 的常用包， 相应教程请先自行网上搜索。 \n",
    "\n",
    "建议您有一定的 numpy, matplotlib, sklearn 基础, 或者还有pandas。 python更是必要的基础知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一部分 一元线性回归\n",
    "\n",
    "pdf 最开始是 Octave 热身， python 相关热身请自行学习。\n",
    "\n",
    "先给出本部分的大纲\n",
    "\n",
    "1. 读取文件里的数据， 进行绘图\n",
    "2. 按模型要求， 准备数据\n",
    "3. 梯度下降， 实现成本函数并测试， 实现梯度下降算法\n",
    "4. 回归直线绘图， 模型应用做预测\n",
    "5. 误差变化过程绘图。 3d 和 轮廓。\n",
    "6. 与 sciki learn 比较。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 可视化起步\n",
    "\n",
    "在开始正式学习之前， 先读取数据,  并绘个图， 有一个直观的印象。\n",
    "\n",
    "### 读取文件中的数据\n",
    "\n",
    "本练习中， 文件读取不难， 要考虑后期使用的方便性。\n",
    "\n",
    "练习： 用 pandas 读取 csv 文件 ex1data1.txt ， 并显示数据的前三行\n",
    "\n",
    "提示： 用 pandas 的话， 注意别把第一行的数据当成列名了， 可以使用names=['population', 'profit']， 用 names = ['x', 'y'] 也可以。\n",
    "\n",
    "其他方案没有考虑，请见谅。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Todo 练习\n",
    "\n",
    "data = pd.read_csv('ex1data1.txt',  names=['population', 'profit'])\n",
    "\n",
    "m = len(data)\n",
    "\n",
    "assert len(data) == 97, \"错误的数据量， 应为97\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n",
    "\n",
    "请先通过上方的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-18598dbe02df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 结果验证\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ex1data1.txt'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'population'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'profit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# 结果验证\n",
    "\n",
    "data = pd.read_csv('ex1data1.txt',  names=['population', 'profit'])\n",
    "print data.size()\n",
    "print data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.1 数据可视化， 绘图\n",
    "\n",
    "使用pyplot, 绘制散点图（scatter 或 plot), 带标题名和横竖坐标名， 最好再调整下范围， x轴上， 5左边太空旷了。\n",
    "\n",
    "提示： 如果使用的是 pandas 读取到的 DataFrame，  data[列名] 得到的是 Series, 不能用， 还需要 data[列名].values 才是得到 ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 轮到你了， 请完成如下任务\n",
    "# 1. 绘制数据的散点图\n",
    "# 2. 坐标轴命名 \n",
    "# 3. 图表命名（指定标题）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(data['population'].values, data['profit'].values)\n",
    "plt.xlabel(\"population\")\n",
    "plt.ylabel(\"profit\")\n",
    "plt.xlim(4, 25)\n",
    "plt.title(u\"一元线性回归\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.2 梯度下降\n",
    "\n",
    "* 预备—— 一元线性回归 $h_\\theta(x) = \\theta_0 + \\theta_1 x_1$\n",
    "\n",
    "*数学公式 latex 编写会不太准确*\n",
    "\n",
    "机器学习三要素——模型、 策略、 算法。  \n",
    "\n",
    "本练习的**模型**为 一元线性回归\n",
    "\n",
    "定义变量：\n",
    "\n",
    "1. 输入数据量大小为 m, 输入表示为 $ \\mathbf{X} $, 输出表示为 $\\mathbf{y} $\n",
    "2. 待学习的权重向量维度为n，  此处 n = 1, 另有第0维,  表示为 $ \\vec{\\theta} = [ \\theta_0, \\theta_1] $， 则有假设函数为：\n",
    "\n",
    "$$ h_\\theta(x) = \\sum\\limits^{n}_{i=0} \\theta_i x_i = \\vec{\\theta}^\\mathrm{T} X $$\n",
    "\n",
    "根据公式， 我们需要:\n",
    "\n",
    "1. 输入变量 x(或X)，  m x (n+1) 维,  第0维初始化为1\n",
    "2. 输出变量 y\n",
    "3. 权重向量变量  theta\n",
    "\n",
    "方案一 使用pandas：\n",
    "\n",
    "变量 x 为DataFrame, 有两个列， x0 和 x1,  其中， x0 列的值全部为 1\n",
    "\n",
    "变量 theta 初始化为[0, 0] 的 ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 轮到你了\n",
    "# 任务如下：\n",
    "# 1. 变量 x ,  m x (n+1)维的np.array， 第0维（即第一列）初始化为1\n",
    "# 2. 变量 y,  一维列向量 np.array\n",
    "# 3. 权重向量变量 theta, \n",
    "\n",
    "x = None\n",
    "y = None\n",
    "theta = None\n",
    "\n",
    "assert type(x) == np.ndarray and x.shape == (97, 2),         \"x 是 m x (n+1)维的numpy.array 数组\"\n",
    "assert type(y) == np.ndarray and y.shape == (97, ),           \"y 是 m x 1维的numpy.array 数组\"\n",
    "assert type(theta) == np.ndarray and theta.shape == (2, ), \"theta 是 2 x 1维的numpy.array 数组\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n",
    "\n",
    "请先通过上方的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame()\n",
    "x['x0'] = np.ones(len(data))\n",
    "x['x1'] = data['population']\n",
    "\n",
    "x = x.values\n",
    "y = data['profit'].values\n",
    "theta = np.zeros(2)\n",
    "\n",
    "print x.shape, y.shape, theta.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 选择策略 —— 误差函数成本函数 (cost function)\n",
    "\n",
    "回归分析一般都使用均方根误差、 拟合标准差 (RMSE  Root mean squared error),  但此处 ng 使用的是均方差(MSE) 再除常数2。\n",
    "\n",
    "$ J(\\theta) = \\frac{1}{2m} \\sum\\limits^{m}_{i=1}(h_\\theta(x^i) - y^i)^2 = \\frac{1}{2m} \\Vert X\\theta - y \\Vert^2_2$\n",
    "\n",
    "i 表示 第i条数据， 即第i行的值\n",
    "\n",
    "请实现该函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 轮到你了\n",
    "# 实现 上方公式的 成本函数\n",
    "\n",
    "def compute_cost(x, y, theta):\n",
    "    return 0\n",
    "\n",
    "j_val = compute_cost(x, y, theta)\n",
    "print j_val\n",
    "\n",
    "assert abs(j_val - 32.0727338775) < 0.0001, \"成本函数实现错误\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n",
    "\n",
    "请先通过上方的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(x, y, theta):\n",
    "    x_ = np.dot(x, theta.T) - y\n",
    "    return sum(x_ * x_) / (2 * len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 计算初始的误差值\n",
    "\n",
    "即 theta = [0 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 验证 compute_cost ， 不需要你自己练习代码\n",
    "\n",
    "j_val = compute_cost(x, y, theta)\n",
    "print j_val\n",
    "\n",
    "assert abs(j_val - 32.0727338775) < 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* 梯度下降参数初始化\n",
    "\n",
    "迭代次数及学习率$\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations = 1500\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 运行梯度下降\n",
    "\n",
    "$ \\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\sum\\limits^{m}_{i=1}(h_\\theta(x^i) - y^i)x^i_j$\n",
    "\n",
    "$ \\theta = \\theta - \\alpha\\vec{\\theta}^\\mathrm{T} X $\n",
    "\n",
    "请实现梯度下降法的函数——这部分的推导先推后。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 轮到你了\n",
    "def gradient_descent(x, y, theta, alpha, iterations):\n",
    "\n",
    "    theta_trace = []\n",
    "    return theta, theta_trace\n",
    "\n",
    "theta, theta_trace = gradient_descent(x, y, theta, alpha, iterations)\n",
    "\n",
    "assert np.allclose(theta, [-3.630291, 1.166362]),  “结果不正确”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n",
    "\n",
    "请先通过上方的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, theta, alpha, iterations):\n",
    "    theta_trace = [theta]\n",
    "\n",
    "    m = len(x)\n",
    "    for i in range(iterations):\n",
    "        x_ = np.dot(x.T, np.dot(x, theta.T) - y) \n",
    "        \n",
    "        theta = theta - alpha * x_ / m\n",
    "        theta_trace.append(theta)\n",
    "        #print compute_cost(x, y, ntheta)\n",
    "    return theta, theta_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta, theta_trace = gradient_descent(x, y, theta, alpha, iterations)\n",
    "theta_array = np.array(theta_trace)\n",
    "print 'Theta found by gradient descent: '\n",
    "print \"%f %f \" % tuple(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* 根据模型绘图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(data['population'].values, data['profit'].values, color = 'red')\n",
    "plt.plot(data['population'].values, np.dot(x, theta), color='blue')\n",
    "plt.xlabel(\"population\")\n",
    "plt.ylabel(\"profit\")\n",
    "plt.xlim(4, 25)\n",
    "plt.title(\"linear regression result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* 预测\n",
    "\n",
    "预测人口 为35000 和 70000时的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 轮到你了\n",
    "\n",
    "pred_y = np.array([0, 0])\n",
    "assert np.allclose(pred_y*10000, [ 4519.767868, 45342.450129])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n",
    "\n",
    "请先通过上方的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_x = np.array([[1, 3.5], [1, 7]])\n",
    "\n",
    "pred_y = np.dot(pred_x, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'For population = 35,000, we predict a profit of %f\\n'  % (pred_y[0] * 10000)\n",
    "print 'For population = 70,000, we predict a profit of %f\\n'  % (pred_y[1] * 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对误差函数进行可视化分析\n",
    "\n",
    "初始化 theta0 , theta1 两个变量， 使用 np.linspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 轮到你了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n",
    "\n",
    "请先通过上方的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta0 = np.linspace(-10, 10, 100)\n",
    "theta1 = np.linspace(-1, 4, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化 J_vals 为一个 0 矩阵， theta0 x theta1 维\n",
    "\n",
    "计算各点 对应的 误差值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 轮到你了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n",
    "\n",
    "请先通过上方的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "J_vals = np.zeros((len(theta0), len(theta1)))\n",
    "\n",
    "for i in range(len(theta0)):\n",
    "    for j in range(len(theta1)):\n",
    "        t = np.array([theta0[i], theta1[j]])\n",
    "        J_vals[i][j] = compute_cost(x, y, t)\n",
    "\n",
    "minpos = J_vals.argmin() \n",
    "miny= minpos % len(theta0)\n",
    "minx = minpos / len(theta0)\n",
    "print J_vals.min(), '  at  ', theta0[minx], theta1[miny] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3d绘图\n",
    "\n",
    "提示： \n",
    "\n",
    "1. 3d 绘图可使用 mpl_toolkits.mplot3d.axes3d \n",
    "2. 函数是 plot_surface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 轮到你了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n",
    "\n",
    "请先通过上方的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "xzim, yzim = np.meshgrid(theta0, theta1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = p3.Axes3D(fig)\n",
    "ax.scatter(theta[0], theta[1], compute_cost(x, y, theta), color='r')\n",
    "ax.plot_surface(xzim, yzim, J_vals.T, color='g', alpha=.5)\n",
    "\n",
    "ax.set_xlabel('theta0')\n",
    "ax.set_ylabel('theta1')\n",
    "ax.set_zlabel(' J ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 轮廓绘图\n",
    "\n",
    "**注** 因为 contour 的meshgrid 性质， J_vals 需要转置。 我也不知道——反正要转置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.contour( theta0, theta1,  J_vals.T, np.logspace(-2, 3, 20))\n",
    "plt.xlabel('theta0')\n",
    "plt.ylabel('theta1')\n",
    "plt.scatter(-3.630291, 1.166362 )\n",
    "plt.scatter(0, 0)\n",
    "plt.scatter(-3.737, 1.17171717172)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 比较\n",
    "与 sklearn 或 scipy 的现成结果比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as lm\n",
    "columns = data.columns[:-1]\n",
    "model = lm()\n",
    "model.fit(data[columns].values, data['profit'].values)\n",
    "print \"sklearn 得到的结果     为: 截距 %f    斜率  %f \"  % (model.intercept_, model.coef_)\n",
    "print \"你实现的梯度下降结果为: 截距 %f    斜率  %f \" % tuple(theta)\n",
    "pred = model.predict(data[columns].values)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(data['population'].values, data['profit'].values)\n",
    "plt.xlabel(\"population\")\n",
    "plt.ylabel(\"profit\")\n",
    "plt.xlim(4, 25)\n",
    "plt.title(u\"linear regression\")\n",
    "prd = model.predict(data[columns].values)\n",
    "plt.plot(data['population'].values, prd, color='red')\n",
    "plt.plot(data['population'].values, np.dot(x, theta) , color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二部分 多元线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 数据读取， 读取文件 ex1data2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ex1data2.txt',  names=['size', 'bedroom', 'price'])\n",
    "\n",
    "X = data[data.columns[:-1]]\n",
    "y = data['price']\n",
    "print X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n",
    "\n",
    "请先通过上方的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ex1data2.txt',  names=['size', 'bedroom', 'price'])\n",
    "\n",
    "X = data[data.columns[:-1]]\n",
    "y = data['price']\n",
    "print X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 特征归一化 feature normalize, feature scale\n",
    "\n",
    "有助于算法快速收敛，可以通过迭代算法的公式来解释\n",
    "\n",
    "将特征的取值范围归到 0-1 或 -1-1之间。\n",
    "\n",
    "0-1 转换： X_norm = (X - min) / (max - min)\n",
    "\n",
    "-1 - 1 转换 :  X_norm = (X - mean) / std 或 (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 轮到你了\n",
    "# 返回归一化后的X， 及 原X 各特征的平均值、 标准方差\n",
    "def feature_normalize(X):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n",
    "\n",
    "请先通过上方的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_normalize(X):\n",
    "    mu = X.mean()\n",
    "    sigma = X.std()\n",
    "    X = (X - mu) / sigma\n",
    "        \n",
    "    return X, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数据进行归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, mu, sigma = feature_normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好要线性回归需要的X, y\n",
    "\n",
    "要给上面的特征值添加新的一列， 代表 theta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 轮到你了\n",
    "\n",
    "print X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n",
    "\n",
    "请先通过上方的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X['x0'] = np.ones(len(data))\n",
    "print X.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 梯度下降\n",
    "\n",
    "如果一元线性回归的梯度下降函数利用了矩阵相乘的方法， 则可以直接用于多元线性回归， 默认可以使用\n",
    "\n",
    "参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.01;\n",
    "num_iters = 400;\n",
    "theta = np.zeros(X.shape[1])\n",
    "print X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算 theta 权重向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta, theta_trace = gradient_descent(X, y, theta, alpha, num_iters)\n",
    "print theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习速率的选取\n",
    "\n",
    "暂空缺"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 正规方程\n",
    "\n",
    "闭合解(closed-form):\n",
    "\n",
    "由方程:\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\Vert X\\theta - y \\Vert^2_2 $$\n",
    "\n",
    "去掉常系数 1/2m, 求导得：\n",
    "\n",
    "$$ \\frac{dJ}{d\\theta}(\\theta) =  \\theta X^\\mathrm{T}X - X^\\mathrm{T} y$$\n",
    "\n",
    "极值（最小值）出现于导数为0时——有前提， 令上式=0\n",
    "\n",
    "求得 \n",
    "\n",
    "$$ \\theta = (X^\\mathrm{T} X) ^{ -1} X^\\mathrm{T} y $$\n",
    "\n",
    "可知， $$ X^\\mathrm{T} X $$ 必须为可逆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 轮到你了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码\n",
    "\n",
    "请先通过上方的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normal_eqn(X, y):\n",
    "    return np.dot( np.dot( np.linalg.inv(np.dot(X.T, X)), X.T), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data[data.columns[:-1]]\n",
    "X['x0'] = np.ones(len(data))\n",
    "X = X[['x0', 'size', 'bedroom']]\n",
    "\n",
    "y = data['price']\n",
    "\n",
    "print normal_eqn(X.values, y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本练习到此为止， 谢谢\n",
    "\n",
    "### 前面缺漏的将尽快补充， 如有错误恳请指正"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
